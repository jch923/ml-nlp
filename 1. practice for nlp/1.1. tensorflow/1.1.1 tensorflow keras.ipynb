{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 tensorflow - keras\n",
    "___________________________________________________\n",
    "## 텐서플로는 마치 블록을 하나씩 쌓아서 전체 구조를 만들어가는 것과 같은 딥러닝 모델을 만듬\n",
    "## 이 블록 역할을 할 수 있는 모듈 중 하나가 케라스(Keras)\n",
    "## 케라스는 텐서플로와 같은 별개의 딥러닝 오픈소스이나 텐서플로에서도 사용 가능\n",
    "## 케라스는 텐서플로와 비교해서 사용법이 좀더 직관적이고 쉽다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers\n",
    "________________________________________________________________\n",
    "#### 라이브러리 불러오기 및 상수값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "# 실습코드는 1.0기준이므로 2.0에서 사용할 수 있도록 설정\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수값 설정\n",
    "\n",
    "# 신경망에 쓰이는 입력 값의 사이즈\n",
    "INPUT_SIZE = (20, 1) \n",
    "# 합성곱 신경망에 쓰이는 입력 값의 사이즈\n",
    "CONV_INPUT_SIZE = (1, 28, 28)\n",
    "#\n",
    "IS_TRAINING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer (신경망 구조의 가장 기본적인 형태)\n",
    "_________________________________________________________________________________________\n",
    "#### Dense: y = f ( Wx + b )의 수식을 만족하는 기본적인 신경망 형태의 층을 만드는 함수, 케라스의 모듈 중 하나\n",
    "#### x: 입력 벡터, b = 편향 벡터, w = 가중치 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 값으로 10개의 값을 출력하는 완전 연결 계층(Fully Connected Layer)\n",
    "\n",
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE) \n",
    "# 10개의 출력 값\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input) \n",
    "\n",
    "# units: 출력값의 크기\n",
    "# activation: 활성화 함수(여기선 sigmoid함수 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer with 1 hidden layer (은닉층이 있는 신경망)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개의 노드를 가지는 은닉층이 있고 최종 출력값은 2개의 노드가 있는 신경망 구조\n",
    "\n",
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE) \n",
    "# 10개의 노드를 가지는 은닉 층\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input)\n",
    "# 2개의 최종 출력 값\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout (드롭아웃)\n",
    "______________________________________________________________________________________\n",
    "#### 신경망 모델을 만들때 생기는 문제 중 하나인 과적합(Overfitting)해결을 위해 사용\n",
    "#### 여기선 과적합 문제해결을 위해 드롭아웃(dropout)을 통한 정규화(Regularization)방법을 이용하여 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "# 확률이 50%인 dropout 적용\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.5)(input)\n",
    "\n",
    "#rate: 드롭아웃을 적용할 확률, 0~1값을 받음(ex) 0.5 = 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer with 1 hidden layer and dropout(은닉층이 있는 신경망에 드롭아웃 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = INPUT_SIZE)\n",
    "# 확률이 20%인 dropout 적용\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "# 10개의 노드를 가지는 은닉 층\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)\n",
    "# 2개의 최종 출력 값\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer (합성 곱 신경망)\n",
    "___________________________________________________________________________________\n",
    "#### 텐서플로의 합성곱 연산은 Conv1D, Conv2D, Conv3D로 나눠짐\n",
    "#### 자연어 처리 분야에서 사용하는 합성곱은 각 단어(혹은 문자) 벡터의 차원 전체에 대해 필터를 적용시키기 위해 주로 Conv1D를 사용\n",
    "#### Conv1D방식은 가로 방향으로 연산하며 출력값은 벡터가 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)\n",
    "# 크기 3, 필터 10개인 합성곱 적용\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(input)\n",
    "\n",
    "# filters: 필터의 개수, 출력의 차원수\n",
    "# kernel_size: 필터의 크기, 합성곱이 적용되는 윈도우의 길이, 필터의 입력값의 차원수와 높이가 동일하게 연산되기 때문에 가로 길이만 필요하다\n",
    "# padding: 패딩방법, 'valid'와 'same'지정 가능\n",
    "# activation: 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer with dropout(입력 값에 드롭아웃을 적용한 합성곱 신경망)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)\n",
    "# 20%확률의 드롭아웃 적용\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(input)\n",
    "# 크기 3, 필터 10개인 합성곱 적용\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(dropout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-Pooling(맥스 풀링)\n",
    "____________________________________________________________________________________________________________________________\n",
    "#### 풀링: 합성곱 신경망과 함께 쓰이는 기법중 하나\n",
    "#### 피처 맵(feature map)의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법\n",
    "#### 맥스 풀링은 피처맵에 대해 최댓값만을 뽑아내는 방식\n",
    "#### 맥스 풀링 또한 MaxPool1D, MaxPool2D, MaxPool3D로 나뉨\n",
    "#### 자연어 처리에서는 합성곱과 동일하게 MaxPool1D를 주로 사용, 한방향으로만 풀링이 진행됨\n",
    "#### 사용법은 합성곱과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input -> Dropout -> Convolutional layer -> MaxPooling -> Dense layer with 1 hidden layer -> Output\n",
    "\n",
    "# 입력 값\n",
    "input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)\n",
    "# 확률 20%의 드롭아웃\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.2)(input)\n",
    "# 크기 3, 필터 10개인 합성곱 적용\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(dropout)\n",
    "# 크기 3의 맥스 풀링 적용\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)\n",
    "# flatten 적용(행렬을 벡터로 변환)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "# 50개의 노드를 가지는 은닉 층, 활성화 함수는 relu 함수 사용\n",
    "hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)\n",
    "# 10개의 최종 출력 값 출력\n",
    "output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)  \n",
    "\n",
    "# flatten: 맥스 풀링 결과값을 완전 연결 계층으로 연결하기 위해 행렬이었던 것을 벡터로 만들어준다\n",
    "# pool_size: 풀링을 적용할 필터의 크기\n",
    "# padding: 패딩 방법, 'valid'와 'same' 지정 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
