{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 한글 토크나이징 라이브러리\n",
    "### 한글은 언어 특성상 영어를 위한 도구를 사용하기에는 적합하지 않다.(현태소 분석, 음소 분리 등)\n",
    "### 한글 자연어 처리에 많이 사용하는 파이썬 라이브러리로 KoNLPy가 있다.\n",
    "\n",
    "### KoNLPy\n",
    "#### KoNLPy는 한글 자연어 처리를 쉽고 간결하게 처리할 수 있도록 만들어진 오픈소스 라이브러리이다.\n",
    "#### 국내에 이미 만들어져 사용되고 있는 여러 형태소 분석기를 사용할 수 있게 허용한다.\n",
    "#### 형태소 분석으로 형태소 단위의 토크나이징을 가능하게 하고, 구문 분석을 가능하게 해서 언어 분석을 하는 데 유용한 도구다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형태소 단위 토크나이징\n",
    "##### 한글의 경우 형태소 단위 토크나이징이 필요할 때가 있다.\n",
    "##### KoNLPy에서는 여러 형태소 분석기를 제공하며, 각 분석기별로 분석한 결과는 다를 수 있다.\n",
    "##### 각 분석기는 클래스 형태로 돼있고, 이를 객체로 생성한 후 메서드를 호출해서 토크나이징할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형태소 분석 및 품사 태깅\n",
    "##### 형태소란 의미를 가지는 가장 작은 단위로서 더 쪼개면 의미를 상실하는 것들을 말한다.\n",
    "##### 즉, 형태소 분석이란 의미르르 가지는 단위를 기준으로 문장을 살펴보는 것을 의미한다.\n",
    "##### KoNLPy에는 다음과 같은 형태소 분석기가 있다.\n",
    "###### - Hannanum\n",
    "###### - Kkma\n",
    "###### - Komoran\n",
    "###### - Mecab                      * 윈도우에서 사용 불가\n",
    "###### - Okt(Twitter)\n",
    "##### 각기 성능이 조금씩 다르므로 직접 비교해보고 자신의 데이터를 가장 잘 분석하는 분석기 사용을 권장한다.\n",
    "##### 이번 실습에서는 Okt를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#konlpy에서 Okt를 불러온다\n",
    "import konlpy\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt객체를 생성한다\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Okt는 다음과 같은 4개의 함수를 제공한다.\n",
    "###### okt.morphs(): 텍스트를 형태소 단위로 나눈다. 옵션으로는 norm과 stem이 있다. 각각 True 혹은 False 값을 받으며, norm은 normalize의 약자로서 문장을 정규화 하는 역할을 하고, stem은 각 단어에서 어간을 추출하는 기능이다. 각각 True로 설정하면 각 기능이 적용된다. 옵션을 지정하지 않으면 기본값은 둘 다 False로 설정된다.\n",
    "###### okt.nouns(): 텍스트에서 명사만 뽑아낸다.\n",
    "###### okt.phrases(): 텍스트에서 어절을 뽑아낸다.\n",
    "###### okt.pos(): 위의 세 함수는 어간/명사/어절 등을 추출해내는 추출기로 동작했다면 pos함수는 각 품사를 태깅하는 역할을 한다. 품사를 태깅한다는 것은 주어진 텍스트를 형태소 단위로 나누고 , 나눠진 각 형태소를 그에 해당하는 품사와 함께 리스트화 하는 것이다. 이 함수에서도 옵션을 설정할 수 있는데, morphs 함수와 마찬가지로 norm, stem 옵션이 있고 추가적으로 join 함수가 있는데 이 옵션값을 True로 설정하면 나눠진 형태소와 품사를 '형태소/품사' 형태로 같이 붙여서 리스트화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n"
     ]
    }
   ],
   "source": [
    "# 임의의 텍스트 생성\n",
    "text = \"한글 자연어 처리는 재밌다 이제부터 열심히 해야지 ㅎㅎㅎ\"\n",
    "# 형태소 단위로 나눈다\n",
    "print(okt.morphs(text))\n",
    "# 형태소 단위로 나눈 후 어간을 추출\n",
    "print(okt.morphs(text, stem=True))\n",
    "\n",
    "# 어간 추출의 경우 '해야지'의 어간인 '하다'로 추출된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '이제']\n",
      "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n"
     ]
    }
   ],
   "source": [
    "# 명사만 추출\n",
    "print(okt.nouns(text))\n",
    "# 어절 단위로 추출\n",
    "print(okt.phrases(text))\n",
    "\n",
    "# 각자 목적에 맞게 결과를 출력함을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "# 형태소와 품사 추출\n",
    "print(okt.pos(text))\n",
    "# 형태소와 품사를 붙여서 리스트화\n",
    "print(okt.pos(text, join=True))\n",
    "\n",
    "# 각자 설정한대로 출력되는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KoNLPy 데이터\n",
    "##### KoNLPy 라이브러리는 한글 자연어 처리에 활용할 수 있는 한글 데이터를 포함하고 있다.\n",
    "##### 데이터의 종류는 다음과 같다.\n",
    "###### kolaw: 한국 법률 말뭉치. 'constitution'파일로 저장돼 있다.\n",
    "###### kobill: 대한민국 국회 의안 말뭉치. 각 id 값을 가지는 의안으로 구성돼 있고 파일은 '189809.txt'부터 '1809899.txt' 까지로 구성돼있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 사용을 위해 각 말뭉치를 불러온다.\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.corpus import kobill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국헌법\\n\\n유구한 역사와 전통에 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 법률 말뭉치중 앞의 20개만 불러온다.\n",
    "kolaw.open('constitution.txt').read()[:20]\n",
    "\n",
    "# 앞의 20가가 출력됨을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국회 의안 말뭉치 중 '1809890.txt' 의안을 불러온다.\n",
    "kobill.open('1809890.txt'.read())\n",
    "\n",
    "# 해당 의안이 출력됨을 확인할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
