{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Logistic Regression Example with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Feature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/' \n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 한 데이터를 불러온다.\n",
    "train_data = pd.read_csv( DATA_IN_PATH + TRAIN_CLEAN_DATA )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰값과 라벨값을 각각 따로 리스트로 지정해둔다.\n",
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000) \n",
    "\n",
    "# min_df: 설정한 값보다 특정 토큰의 df 값이 더 적게 나오면 벡터화 과정에서 제가한다는 의미\n",
    "# analyzer: 분석하기 위한 기준 단위, char의 경우 문자 하나를 단위로 한다\n",
    "# sublinear_tf: 문서의 단어 빈도수에 대한 스무딩 여부를 설정하는 값\n",
    "# ngram_range: 빈도의 기본 단위를 어느 범위의 n-gram으로 설정할 것인가를 보는 인자\n",
    "# max_features: 각 벡터의 최대 길이, 특징의 최대 길이\n",
    "\n",
    "# 전체 문장에 대한 특징 벡터 데이터 X를 생성\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "# 라벨값 넘파이 배열로 생성\n",
    "y = np.array(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17862755 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 20%를 검증 데이터로 따로 분리 \n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression 클래스 객체 선언\n",
    "lgs = LogisticRegression(class_weight='balanced') \n",
    "\n",
    "# class_weighted = 'balanced' : 각 라벨에 대해 균형 있게 학습할 수 있게 지정\n",
    "\n",
    "# 모델 학습 진행\n",
    "lgs.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lgs.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.860000\n"
     ]
    }
   ],
   "source": [
    "# 학습한 모델 성능 측정\n",
    "print(\"Accuracy: %f\" % lgs.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글에 제출할 파일 생성\n",
    "\n",
    "# 파일명 설정\n",
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "# 테스트 데이터를 판다스로 불러온다.\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF값으로 변환\n",
    "testDataVecs = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 예측값 출력\n",
    "test_predicted = lgs.predict(testDataVecs)\n",
    "print(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글에 제출하기 위한 파일 형태로 저장\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "answer_dataset = pd.DataFrame({'id': test_data['id'], 'sentiment': test_predicted})\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
